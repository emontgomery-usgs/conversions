{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate crawler env 1st!\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "import thredds_crawler\n",
    "from thredds_crawler.crawl import Crawl\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first try with a single directory worked great. I can loop through the files the crawler finds, per the example on git-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps='https://gamone.whoi.edu/thredds/silt/usgs/Projects/stellwagen/Data/DAUPHIN/catalog.xml'\n",
    "if type(fps) is str:\n",
    "    print('is a string')\n",
    "    c = Crawl(fps, select=[\".*nc\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<LeafDataset id: silt/usgs/Projects/stellwagen/Data/DAUPHIN/9651hwlb-a.nc, name: 9651hwlb-a.nc, services: ['OPENDAP', 'HTTPServer', 'NetcdfSubset', 'ISO', 'NCML', 'UDDC', 'WMS']>,\n",
       " <LeafDataset id: silt/usgs/Projects/stellwagen/Data/DAUPHIN/9661rb-a.nc, name: 9661rb-a.nc, services: ['OPENDAP', 'HTTPServer', 'NetcdfSubset', 'ISO', 'NCML', 'UDDC', 'WMS']>,\n",
       " <LeafDataset id: silt/usgs/Projects/stellwagen/Data/DAUPHIN/9681dw-a.nc, name: 9681dw-a.nc, services: ['OPENDAP', 'HTTPServer', 'NetcdfSubset', 'ISO', 'NCML', 'UDDC', 'WMS']>,\n",
       " <LeafDataset id: silt/usgs/Projects/stellwagen/Data/DAUPHIN/9691hwl-a.nc, name: 9691hwl-a.nc, services: ['OPENDAP', 'HTTPServer', 'NetcdfSubset', 'ISO', 'NCML', 'UDDC', 'WMS']>,\n",
       " <LeafDataset id: silt/usgs/Projects/stellwagen/Data/DAUPHIN/9701rb-a.nc, name: 9701rb-a.nc, services: ['OPENDAP', 'HTTPServer', 'NetcdfSubset', 'ISO', 'NCML', 'UDDC', 'WMS']>,\n",
       " <LeafDataset id: silt/usgs/Projects/stellwagen/Data/DAUPHIN/9711rb-a.nc, name: 9711rb-a.nc, services: ['OPENDAP', 'HTTPServer', 'NetcdfSubset', 'ISO', 'NCML', 'UDDC', 'WMS']>,\n",
       " <LeafDataset id: silt/usgs/Projects/stellwagen/Data/DAUPHIN/9721rb-a.nc, name: 9721rb-a.nc, services: ['OPENDAP', 'HTTPServer', 'NetcdfSubset', 'ISO', 'NCML', 'UDDC', 'WMS']>,\n",
       " <LeafDataset id: silt/usgs/Projects/stellwagen/Data/DAUPHIN/9731hwl-a.nc, name: 9731hwl-a.nc, services: ['OPENDAP', 'HTTPServer', 'NetcdfSubset', 'ISO', 'NCML', 'UDDC', 'WMS']>,\n",
       " <LeafDataset id: silt/usgs/Projects/stellwagen/Data/DAUPHIN/9741hwl-a.nc, name: 9741hwl-a.nc, services: ['OPENDAP', 'HTTPServer', 'NetcdfSubset', 'ISO', 'NCML', 'UDDC', 'WMS']>,\n",
       " <LeafDataset id: silt/usgs/Projects/stellwagen/Data/DAUPHIN/9751hwl-a.nc, name: 9751hwl-a.nc, services: ['OPENDAP', 'HTTPServer', 'NetcdfSubset', 'ISO', 'NCML', 'UDDC', 'WMS']>,\n",
       " <LeafDataset id: silt/usgs/Projects/stellwagen/Data/DAUPHIN/9761hwl-a.nc, name: 9761hwl-a.nc, services: ['OPENDAP', 'HTTPServer', 'NetcdfSubset', 'ISO', 'NCML', 'UDDC', 'WMS']>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when I try to loop throught more than 1 directory, it doesn't seem to think the string is something it can operate on in crawl.  I've tried with various os* options, glob, and I can't seem to fabricate a way to loop through more than 1 catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dirlist=('ARGO_MERCHANT','BARNEGAT','BARNEGAT_2014','BUZZ_BAY','BW_2011')\n",
    "#dirlist=('CALSCTWET','CAMP','CAPE_COD_BAY','CC_MISC','CHANDELEUR_13','CHINCOTEAGUE')\n",
    "#dirlist=('DAUPHIN','DEEP_REEF','DIAMONDSHOALS','DWDS_106','ECOHAB_I','ECOHAB_II','EUROSTRATAFORM')\n",
    "dirlist=('DAUPHIN','DEEP_REEF')  \n",
    "proot='https://gamone.whoi.edu/thredds/silt/usgs/Projects/stellwagen/Data/'\n",
    "sufx='/catalog.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is a string\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0d04ee9f1387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'is a string'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrawl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\".*nc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/crawler/lib/python3.6/site-packages/thredds_crawler/crawl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, catalog_url, select, skip, before, after, debug, workers, auth)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisited\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0murls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatalog_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mjobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/crawler/lib/python3.6/site-packages/thredds_crawler/crawl.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, url, auth)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Crawling: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_catalog_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Get an etree object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/crawler/lib/python3.6/site-packages/thredds_crawler/crawl.py\u001b[0m in \u001b[0;36m_get_catalog_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mstr\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mURL\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcatalog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         '''\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\".html\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/crawler/lib/python3.6/urllib/parse.py\u001b[0m in \u001b[0;36murlsplit\u001b[0;34m(url, scheme, allow_fragments)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0mNote\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mbreak\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcomponents\u001b[0m \u001b[0mup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmaller\u001b[0m \u001b[0mbits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_coerce_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_coerce_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0mallow_fragments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallow_fragments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fragments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/crawler/lib/python3.6/urllib/parse.py\u001b[0m in \u001b[0;36m_coerce_args\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_noop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decode_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_encode_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;31m# Result objects are more helpful than simple tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/crawler/lib/python3.6/urllib/parse.py\u001b[0m in \u001b[0;36m_decode_args\u001b[0;34m(args, encoding, errors)\u001b[0m\n\u001b[1;32m    105\u001b[0m def _decode_args(args, encoding=_implicit_encoding,\n\u001b[1;32m    106\u001b[0m                        errors=_implicit_errors):\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_coerce_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/crawler/lib/python3.6/urllib/parse.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    105\u001b[0m def _decode_args(args, encoding=_implicit_encoding,\n\u001b[1;32m    106\u001b[0m                        errors=_implicit_errors):\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_coerce_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "for idx in dirlist:\n",
    "    fpath=[proot + idx + sufx] \n",
    "    if type(fps) is str:\n",
    "        print('is a string')\n",
    "        c = Crawl(fpath, select=[\".*nc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:crawler]",
   "language": "python",
   "name": "conda-env-crawler-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
